{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a custom bundle for Zipline using Stock data; see download instructions first.\n",
    "\n",
    "## We will take the following steps:\n",
    "\n",
    "Create several data files containing information on tickers, prices, and adjustments\n",
    "Code up a Zipline ingest function that handles the data processing and storage\n",
    "Define a Zipline extension that registers the new bundle\n",
    "Place the files in the Zipline_ROOT directory to ensure the Zipline ingest command finds them\n",
    "Setup\n",
    "Zipline permits the creation of custom bundle containing open, high, low, close and volume (OHCLV) information, as well as adjustments like stock splits and dividend payments.\n",
    "\n",
    "It stores the data per default a .Zipline directory in the user's home directory, ~/.Zipline. However, you can modify the target location by setting the Zipline_ROOT environment variable as we do for the docker images provided with this book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "To prepare the data, we create three kinds of data tables in HDF5 format:\n",
    "\n",
    "equities: contains a unique sid, the ticker, and a name for the security.\n",
    "price tables with OHLCV data for each of the assets, named jp.<sid>\n",
    "splits: contains split factors and is required; our data is already adjusted so we just add one line with a factor of 1.0 for one\n",
    "The file stooq_preprocessing implements these steps and produces the tables in the HDF5 file stooq.h5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipline ingest function\n",
    "The file stooq_jp_stocks.py defines a function stooq_jp_to_bundle(interval='1d') that returns the ingest function required by Zipline to produce a custom bundle (see docs. It needs to have the following signature:\n",
    "\n",
    "ingest(environ,\n",
    "       asset_db_writer,\n",
    "       minute_bar_writer,\n",
    "       daily_bar_writer,\n",
    "       adjustment_writer,\n",
    "       calendar,\n",
    "       start_session,\n",
    "       end_session,\n",
    "       cache,\n",
    "       show_progress,\n",
    "       output_dir)\n",
    "This function loads the information we crated in the previous step during the ingest process. It consists of a data_generator() that loads (sid, ticker) tuples as needed, and produces the corresponding OHLCV info in the correct format. It also adds information about the exchange so Zipline can associate the right calendar, and the range of trading dates.\n",
    "\n",
    "It also loads the adjustment data, which in this case does not play an active role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundle registration\n",
    "Zipline needs to know that the bundle exists and how to create the ingest function we just defined. To this end, we create an extension.py file that communicates the bundle's name, where to find the function that returns the ingest function (namely stooq_jp_to_bundle() in stooq_jp_stocks.py), and indicates the trading calendar to use (NYMEX for NY's exchange)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File locations\n",
    "Finally, we need to put these files in the right locations so that Zipline finds them. We can use symbolic links while keeping the actual files in this directory.\n",
    "\n",
    "More specifically, we'll create symbolic links to\n",
    "\n",
    "to stooq_jp_stocks.py in the ZIPLINE_ROOT directory, and\n",
    "to stooq.h5 in ZIPLINE_ROOT/custom_data\n",
    "In Linux or MacOSX, this implies opening the shell and running the following commands (where PROJECT_DIR refers to absolute path to the root folder of this repository on your machine)\n",
    "\n",
    "cd $ZIPLINE_ROOT\n",
    "ln -s PROJECT_DIR/11_decision_trees_random_forests/00_custom_bundle/stooq_jp_stocks.py\n",
    "ln -s PROJECT_DIR/machine-learning-for-trading/11_decision_trees_random_forests/00_custom_bundle/extension.py .\n",
    "mkdir custom_data\n",
    "ln -s PROJECT_DIR/11_decision_trees_random_forests/00_custom_bundle/stooq.h5 custom_data/.\n",
    "As a result, your directory structure should look as follows (some of these files will be symbolic links):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(Path('~', '.zipline').expanduser().as_posix())\n",
    "from zipline.data.bundles import register\n",
    "from stooq_jp_stocks import stooq_jp_to_bundle\n",
    "from datetime import time\n",
    "from pytz import timezone\n",
    "\n",
    "\n",
    "register('stooq',\n",
    "         stooq_jp_to_bundle(),\n",
    "         calendar_name='XTKS',\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "zipline_root = None\n",
    "\n",
    "try:\n",
    "    zipline_root = os.environ['ZIPLINE_ROOT']\n",
    "except KeyError:\n",
    "    print('Please ensure a ZIPLINE_ROOT environment variable is defined and accessible '\n",
    "          '(or alter the script and manually set the path')\n",
    "    exit()\n",
    "\n",
    "custom_data_path = Path(zipline_root, 'custom_data')\n",
    "\n",
    "# custom_data_path = Path('~/.zipline/custom_data').expanduser()\n",
    "\n",
    "\n",
    "def load_equities():\n",
    "    return pd.read_hdf(custom_data_path / 'stooq.h5', 'jp/equities')\n",
    "\n",
    "\n",
    "def ticker_generator():\n",
    "    \"\"\"\n",
    "    Lazily return (sid, ticker) tuple\n",
    "    \"\"\"\n",
    "    return (v for v in load_equities().values)\n",
    "\n",
    "\n",
    "def data_generator():\n",
    "    for sid, symbol, asset_name in ticker_generator():\n",
    "        df = pd.read_hdf(custom_data_path / 'stooq.h5', 'jp/{}'.format(sid))\n",
    "\n",
    "        start_date = df.index[0]\n",
    "        end_date = df.index[-1]\n",
    "\n",
    "        first_traded = start_date.date()\n",
    "        auto_close_date = end_date + pd.Timedelta(days=1)\n",
    "        exchange = 'XTKS'\n",
    "\n",
    "        yield (sid, df), symbol, asset_name, start_date, end_date, first_traded, auto_close_date, exchange\n",
    "\n",
    "\n",
    "def metadata_frame():\n",
    "    dtype = [\n",
    "        ('symbol', 'object'),\n",
    "        ('asset_name', 'object'),\n",
    "        ('start_date', 'datetime64[ns]'),\n",
    "        ('end_date', 'datetime64[ns]'),\n",
    "        ('first_traded', 'datetime64[ns]'),\n",
    "        ('auto_close_date', 'datetime64[ns]'),\n",
    "        ('exchange', 'object'), ]\n",
    "    return pd.DataFrame(np.empty(len(load_equities()), dtype=dtype))\n",
    "\n",
    "\n",
    "def stooq_jp_to_bundle(interval='1d'):\n",
    "    def ingest(environ,\n",
    "               asset_db_writer,\n",
    "               minute_bar_writer,\n",
    "               daily_bar_writer,\n",
    "               adjustment_writer,\n",
    "               calendar,\n",
    "               start_session,\n",
    "               end_session,\n",
    "               cache,\n",
    "               show_progress,\n",
    "               output_dir\n",
    "               ):\n",
    "        metadata = metadata_frame()\n",
    "\n",
    "        def daily_data_generator():\n",
    "            return (sid_df for (sid_df, *metadata.iloc[sid_df[0]]) in data_generator())\n",
    "\n",
    "        daily_bar_writer.write(daily_data_generator(), show_progress=True)\n",
    "\n",
    "        metadata.dropna(inplace=True)\n",
    "        asset_db_writer.write(equities=metadata)\n",
    "        # empty DataFrame\n",
    "        adjustment_writer.write(splits=pd.read_hdf(custom_data_path / 'stooq.h5', 'jp/splits'))\n",
    "\n",
    "    return ingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = Path('..', '..', 'data')\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "\n",
    "def create_split_table():\n",
    "    with pd.HDFStore('stooq.h5') as store:\n",
    "        store.put('jp/splits', pd.DataFrame(columns=['sid', 'effective_date', 'ratio'],\n",
    "                                            data=[[1, pd.to_datetime('2010-01-01'), 1.0]]), format='t')\n",
    "\n",
    "\n",
    "def load_prices():\n",
    "    df = pd.read_hdf(DATA_DIR / 'assets.h5', 'stooq/jp/tse/stocks/prices')\n",
    "\n",
    "    return (df.loc[idx[:, '2014': '2019'], :]\n",
    "            .unstack('ticker')\n",
    "            .sort_index()\n",
    "            .tz_localize('UTC')\n",
    "            .ffill(limit=5)\n",
    "            .dropna(axis=1)\n",
    "            .stack('ticker')\n",
    "            .swaplevel())\n",
    "\n",
    "\n",
    "def load_symbols(tickers):\n",
    "    df = pd.read_hdf(DATA_DIR / 'assets.h5', 'stooq/jp/tse/stocks/tickers')\n",
    "    return (df[df.ticker.isin(tickers)]\n",
    "            .reset_index(drop=True)\n",
    "            .reset_index()\n",
    "            .rename(columns={'index': 'sid'}))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    prices = load_prices()\n",
    "    print(prices.info(null_counts=True))\n",
    "    tickers = prices.index.unique('ticker')\n",
    "\n",
    "    symbols = load_symbols(tickers)\n",
    "    print(symbols.info(null_counts=True))\n",
    "    symbols.to_hdf('stooq.h5', 'jp/equities', format='t')\n",
    "\n",
    "    dates = prices.index.unique('date')\n",
    "    start_date = dates.min()\n",
    "    end_date = dates.max()\n",
    "\n",
    "    for sid, symbol in symbols.set_index('sid').symbol.items():\n",
    "        p = prices.loc[symbol]\n",
    "        p.to_hdf('stooq.h5', 'jp/{}'.format(sid), format='t')\n",
    "\n",
    "    with pd.HDFStore('stooq.h5') as store:\n",
    "        print(store.info())\n",
    "\n",
    "    create_split_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
