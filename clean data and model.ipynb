{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation of data into factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "# from pyfinance.ols import PandasRollingOLS\n",
    "# replaces pyfinance.ols.PandasRollingOLS (no longer maintained)\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import statsmodels.api as sm\n",
    "from talib import RSI, BBANDS, MACD, NATR, ATR\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading US stock data for at least 12 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_STORE = '../data/assets.h5'\n",
    "\n",
    "YEAR = 12\n",
    "\n",
    "START = 1998\n",
    "END = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    prices = (store['quandl/wiki/prices']\n",
    "              .loc[idx[str(START):str(END), :], :]\n",
    "              .filter(like='adj_')\n",
    "              .dropna()\n",
    "              .swaplevel()\n",
    "              .rename(columns=lambda x: x.replace('adj_', ''))\n",
    "              .join(store['us_equities/stocks']\n",
    "                    .loc[:, ['sector']])\n",
    "              .dropna())\n",
    "    \n",
    "prices.info(null_counts=True)\n",
    "\n",
    "len(prices.index.unique('ticker'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing where data less than 10 years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_obs = 10 * 252\n",
    "nobs = prices.groupby(level='ticker').size()\n",
    "to_drop = nobs[nobs < min_obs].index\n",
    "prices = prices.drop(to_drop, level='ticker')\n",
    "\n",
    "prices.info(null_counts=True)\n",
    "\n",
    "len(prices.index.unique('ticker'))\n",
    "\n",
    "prices['rsi'] = prices.groupby(level='ticker').close.apply(RSI)\n",
    "\n",
    "sns.distplot(prices.rsi);\n",
    "\n",
    "\n",
    "def compute_bb(close):\n",
    "    high, mid, low = BBANDS(np.log1p(close), timeperiod=20)\n",
    "    return pd.DataFrame({'bb_high': high,\n",
    "                         'bb_mid': mid,\n",
    "                         'bb_low': low}, index=close.index)\n",
    "\n",
    "prices = (prices.join(prices\n",
    "                      .groupby(level='ticker')\n",
    "                      .close\n",
    "                      .apply(compute_bb)))\n",
    "\n",
    "prices.info(null_counts=True)\n",
    "\n",
    "prices.filter(like='bb_').describe()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15,4))\n",
    "for i, col in enumerate(['bb_low', 'bb_mid', 'bb_low']):\n",
    "    sns.distplot(prices[col], ax=axes[i])\n",
    "    axes[i].set_title(col);\n",
    "fig.tight_layout();\n",
    "\n",
    "prices['bb_up'] = prices.bb_high.sub(np.log1p(prices.close))\n",
    "prices['bb_down'] = np.log1p(prices.close).sub(prices.bb_low)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10,4))\n",
    "for i, col in enumerate(['bb_down', 'bb_up']):\n",
    "    sns.boxenplot(prices[col], ax=axes[i])\n",
    "    axes[i].set_title(col);\n",
    "fig.tight_layout();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average true length \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_ticker = prices.groupby('ticker', group_keys=False)\n",
    "\n",
    "def compute_atr(stock_data):\n",
    "    atr = ATR(stock_data.high, \n",
    "              stock_data.low, \n",
    "              stock_data.close, \n",
    "              timeperiod=14)\n",
    "    return atr.sub(atr.mean()).div(atr.std())\n",
    "\n",
    "prices['atr'] = by_ticker.apply(compute_atr)\n",
    "\n",
    "sns.distplot(prices.atr);\n",
    "\n",
    "prices['natr'] = by_ticker.apply(lambda x: NATR(high=x.high, low=x.low, close=x.close))\n",
    "\n",
    "sns.distplot(prices.natr[prices.natr<10]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving average convergence/divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_macd(close):\n",
    "    macd = MACD(close)[0]\n",
    "    return macd.sub(macd.mean()).div(macd.std())\n",
    "\n",
    "prices['macd'] = prices.groupby(level='ticker').close.apply(compute_macd)\n",
    "\n",
    "sns.distplot(prices.macd);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define dollar volumes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices['dollar_volume'] = (prices.loc[:, 'close']\n",
    "                           .mul(prices.loc[:, 'volume'], axis=0))\n",
    "\n",
    "prices.dollar_volume /= 1e6\n",
    "\n",
    "prices.to_hdf('data.h5', 'us/equities/prices')\n",
    "\n",
    "prices = pd.read_hdf('data.h5', 'us/equities/prices')\n",
    "prices.info(null_counts=True)\n",
    "\n",
    "last_cols = [c for c in prices.columns.unique(0) if c not in ['dollar_volume', 'volume',\n",
    "                                                              'open', 'high', 'low']]\n",
    "\n",
    "prices = prices.unstack('ticker')\n",
    "\n",
    "data = (pd.concat([prices.dollar_volume.resample('M').mean().stack('ticker').to_frame('dollar_volume'),\n",
    "                   prices[last_cols].resample('M').last().stack('ticker')],\n",
    "                  axis=1)\n",
    "        .swaplevel()\n",
    "        .dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define traded stocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dollar_volume'] = (data.loc[:, 'dollar_volume']\n",
    "                         .unstack('ticker')\n",
    "                         .rolling(window=5*12, min_periods=12)\n",
    "                         .mean()\n",
    "                         .stack()\n",
    "                         .swaplevel())\n",
    "\n",
    "data['dollar_vol_rank'] = (data\n",
    "                           .groupby('date')\n",
    "                           .dollar_volume\n",
    "                           .rank(ascending=False))\n",
    "\n",
    "data = data[data.dollar_vol_rank < 500].drop(['dollar_volume', 'dollar_vol_rank'], axis=1)\n",
    "\n",
    "\n",
    "len(data.index.unique('ticker'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monthly returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_cutoff = 0.01\n",
    "lags = [1, 3, 6, 12]\n",
    "returns = []\n",
    "\n",
    "for lag in lags:\n",
    "    returns.append(data\n",
    "                   .close\n",
    "                   .unstack('ticker')\n",
    "                   .sort_index()\n",
    "                   .pct_change(lag)\n",
    "                   .stack('ticker')\n",
    "                   .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n",
    "                                          upper=x.quantile(1-outlier_cutoff)))\n",
    "                   .add(1)\n",
    "                   .pow(1/lag)\n",
    "                   .sub(1)\n",
    "                   .to_frame(f'return_{lag}m')\n",
    "                   )\n",
    "    \n",
    "returns = pd.concat(returns, axis=1).swaplevel()\n",
    "returns.info(null_counts=True)\n",
    "\n",
    "\n",
    "returns.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "sns.clustermap(returns.corr('spearman'), annot=True, center=0, cmap=cmap);\n",
    "\n",
    "\n",
    "data = data.join(returns).drop('close', axis=1).dropna()\n",
    "data.info(null_counts=True)\n",
    "\n",
    "min_obs = 5*12\n",
    "nobs = data.groupby(level='ticker').size()\n",
    "to_drop = nobs[nobs < min_obs].index\n",
    "data = data.drop(to_drop, level='ticker')\n",
    "\n",
    "\n",
    "len(data.index.unique('ticker'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rolling beta factors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "factor_data = web.DataReader('F-F_Research_Data_5_Factors_2x3', \n",
    "                             'famafrench', \n",
    "                             start=START)[0].drop('RF', axis=1)\n",
    "factor_data.index = factor_data.index.to_timestamp()\n",
    "factor_data = factor_data.resample('M').last().div(100)\n",
    "factor_data.index.name = 'date'\n",
    "factor_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data = factor_data.join(data['return_1m']).dropna().sort_index()\n",
    "factor_data['return_1m'] -= factor_data['Mkt-RF']\n",
    "factor_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 60\n",
    "# betas = (factor_data\n",
    "#          .groupby(level='ticker', group_keys=False)\n",
    "#          .apply(lambda x: PandasRollingOLS(window=min(T, x.shape[0]-1), \n",
    "#                                            y=x.return_1m, \n",
    "#                                            x=x.drop('return_1m', axis=1)).beta)\n",
    "#         .rename(columns={'Mkt-RF': 'beta'}))\n",
    "betas = (factor_data.groupby(level='ticker',\n",
    "                             group_keys=False)\n",
    "         .apply(lambda x: RollingOLS(endog=x.return_1m,\n",
    "                                     exog=sm.add_constant(x.drop('return_1m', axis=1)),\n",
    "                                     window=min(T, x.shape[0]-1))\n",
    "                .fit(params_only=True)\n",
    "                .params\n",
    "                .rename(columns={'Mkt-RF': 'beta'})\n",
    "                .drop('const', axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.describe().join(betas.sum(1).describe().to_frame('total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.describe().join(betas.sum(1).describe().to_frame('total'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "sns.clustermap(betas.corr(), annot=True, cmap=cmap, center=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (data\n",
    "        .join(betas\n",
    "              .groupby(level='ticker')\n",
    "              .shift())\n",
    "       .dropna()\n",
    "       .sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### momentum factors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [3, 6, 12]:\n",
    "    data[f'momentum_{lag}'] = data[f'return_{lag}m'].sub(data.return_1m)\n",
    "    if lag > 3:\n",
    "        data[f'momentum_3_{lag}'] = data[f'return_{lag}m'].sub(data.return_3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = data.index.get_level_values('date')\n",
    "data['year'] = dates.year\n",
    "data['month'] = dates.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data.groupby(level='ticker')[f'return_1m'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "data.sort_index().info(null_counts=True)\n",
    "\n",
    "ax = data.reset_index().groupby('sector').ticker.nunique().sort_values().plot.barh(title='Sector Breakdown')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('# Tickers')\n",
    "sns.despine()\n",
    "plt.tight_layout();\n",
    "\n",
    "with pd.HDFStore('data.h5') as store:\n",
    "    store.put('us/equities/monthly', data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate findings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('target', axis=1)\n",
    "X.sector = pd.factorize(X.sector)[0]\n",
    "\n",
    "mi = mutual_info_regression(X=X, y=data.target)\n",
    "\n",
    "mi_reg = pd.Series(mi, index=X.columns)\n",
    "mi_reg.nlargest(10)\n",
    "\n",
    "mi = mutual_info_classif(X=X, y=(data.target>0).astype(int))\n",
    "\n",
    "mi_class = pd.Series(mi, index=X.columns)\n",
    "mi_class.nlargest(10)\n",
    "\n",
    "mi = mi_reg.to_frame('Regression').join(mi_class.to_frame('Classification'))\n",
    "\n",
    "mi.index = [' '.join(c.upper().split('_')) for c in mi.index]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "for i, t in enumerate(['Regression', 'Classification']):\n",
    "    mi[t].nlargest(20).sort_values().plot.barh(title=t, ax=axes[i])\n",
    "    axes[i].set_xlabel('Mutual Information')\n",
    "fig.suptitle('Mutual Information', fontsize=14)\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
